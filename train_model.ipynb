{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForTokenClassification\n",
    "from transformers import XLMRobertaTokenizerFast, XLMRobertaForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176939</th>\n",
       "      <td>176939</td>\n",
       "      <td>[bank, mand, ir, haji, jua, ,, kota, baru]</td>\n",
       "      <td>[street, street, street, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10853</th>\n",
       "      <td>10853</td>\n",
       "      <td>[perumahan, taman, setiabudi, blok, d23]</td>\n",
       "      <td>[POI, POI, POI, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>35892</td>\n",
       "      <td>[batung, taba, nan, xx, kamp, jua, 5, 25155, l...</td>\n",
       "      <td>[O, O, O, O, street, street, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150941</th>\n",
       "      <td>150941</td>\n",
       "      <td>[d, &amp;amp;, k, batteray, ,, pasar, hitam, ,]</td>\n",
       "      <td>[POI, POI, POI, POI, O, street, street, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133188</th>\n",
       "      <td>133188</td>\n",
       "      <td>[gemi, (, dea, huper, optik, ), ,, haji, nawi,...</td>\n",
       "      <td>[POI, POI, POI, POI, POI, POI, O, street, stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28569</th>\n",
       "      <td>28569</td>\n",
       "      <td>[zae, zakse, i, kotalama, kedungkandang]</td>\n",
       "      <td>[street, street, street, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192368</th>\n",
       "      <td>192368</td>\n",
       "      <td>[gal, antik, cv, jati, permata, indah, raya, c...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289922</th>\n",
       "      <td>289922</td>\n",
       "      <td>[sekar, jepun, iii, 11, kesiman, kertalangu, d...</td>\n",
       "      <td>[street, street, street, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251185</th>\n",
       "      <td>251185</td>\n",
       "      <td>[taman, licin]</td>\n",
       "      <td>[street, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133280</th>\n",
       "      <td>133280</td>\n",
       "      <td>[sup, buah, nd, wonosari-yo, ,, playen]</td>\n",
       "      <td>[POI, POI, POI, street, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             tokens  \\\n",
       "176939  176939         [bank, mand, ir, haji, jua, ,, kota, baru]   \n",
       "10853    10853           [perumahan, taman, setiabudi, blok, d23]   \n",
       "35892    35892  [batung, taba, nan, xx, kamp, jua, 5, 25155, l...   \n",
       "150941  150941        [d, &amp;, k, batteray, ,, pasar, hitam, ,]   \n",
       "133188  133188  [gemi, (, dea, huper, optik, ), ,, haji, nawi,...   \n",
       "...        ...                                                ...   \n",
       "28569    28569           [zae, zakse, i, kotalama, kedungkandang]   \n",
       "192368  192368  [gal, antik, cv, jati, permata, indah, raya, c...   \n",
       "289922  289922  [sekar, jepun, iii, 11, kesiman, kertalangu, d...   \n",
       "251185  251185                                     [taman, licin]   \n",
       "133280  133280            [sup, buah, nd, wonosari-yo, ,, playen]   \n",
       "\n",
       "                                                    label  \n",
       "176939            [street, street, street, O, O, O, O, O]  \n",
       "10853                               [POI, POI, POI, O, O]  \n",
       "35892            [O, O, O, O, street, street, O, O, O, O]  \n",
       "150941         [POI, POI, POI, POI, O, street, street, O]  \n",
       "133188  [POI, POI, POI, POI, POI, POI, O, street, stre...  \n",
       "...                                                   ...  \n",
       "28569                      [street, street, street, O, O]  \n",
       "192368                        [O, O, O, O, O, O, O, O, O]  \n",
       "289922            [street, street, street, O, O, O, O, O]  \n",
       "251185                                        [street, O]  \n",
       "133280                      [POI, POI, POI, street, O, O]  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json(\"train_processed.json\").sample(1000)\n",
    "val_df = pd.read_json(\"val_processed.json\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the tokens and their corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POI', 'O', 'street'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>bank</td>\n",
       "      <td>mand</td>\n",
       "      <td>ir</td>\n",
       "      <td>haji</td>\n",
       "      <td>jua</td>\n",
       "      <td>,</td>\n",
       "      <td>kota</td>\n",
       "      <td>baru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <td>street</td>\n",
       "      <td>street</td>\n",
       "      <td>street</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_id</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1       2     3    4  5     6     7\n",
       "text      bank    mand      ir  haji  jua  ,  kota  baru\n",
       "tag     street  street  street     O    O  O     O     O\n",
       "tag_id       2       2       2     1    1  1     1     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = train_df[\"tokens\"].to_list()\n",
    "train_tags = train_df[\"label\"].to_list()\n",
    "\n",
    "unique_tags = set(tag for label in train_tags for tag in label)\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "\n",
    "train_tag_ids = [[tag2id[tag] for tag in sample] for sample in train_tags]\n",
    "\n",
    "print(unique_tags)\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = train_texts[0]\n",
    "df[\"tag\"] = train_tags[0]\n",
    "df[\"tag_id\"] = train_tag_ids[0]\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "train_encodings = tokenizer(train_texts, is_split_into_words=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input ids</th>\n",
       "      <td>0</td>\n",
       "      <td>4620</td>\n",
       "      <td>14134</td>\n",
       "      <td>193</td>\n",
       "      <td>117790</td>\n",
       "      <td>1129</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>20553</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attention mask</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁bank</td>\n",
       "      <td>▁mand</td>\n",
       "      <td>▁ir</td>\n",
       "      <td>▁haji</td>\n",
       "      <td>▁ju</td>\n",
       "      <td>a</td>\n",
       "      <td>▁</td>\n",
       "      <td>,</td>\n",
       "      <td>▁kota</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0      1      2    3       4     5   6  7  8      9   ...  \\\n",
       "input ids         0   4620  14134  193  117790  1129  11  6  4  20553  ...   \n",
       "attention mask    1      1      1    1       1     1   1  1  1      1  ...   \n",
       "tokens          <s>  ▁bank  ▁mand  ▁ir   ▁haji   ▁ju   a  ▁  ,  ▁kota  ...   \n",
       "\n",
       "                   32     33     34     35     36     37     38     39     40  \\\n",
       "input ids           1      1      1      1      1      1      1      1      1   \n",
       "attention mask      0      0      0      0      0      0      0      0      0   \n",
       "tokens          <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>   \n",
       "\n",
       "                   41  \n",
       "input ids           1  \n",
       "attention mask      0  \n",
       "tokens          <pad>  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"input ids\"] = train_encodings[\"input_ids\"][idx]\n",
    "df[\"attention mask\"] = train_encodings[\"attention_mask\"][idx]\n",
    "df[\"tokens\"] = tokenizer.convert_ids_to_tokens(train_encodings[\"input_ids\"][idx])\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align the labels\n",
    "\n",
    "The tokenizer use sub-word tokenization, thus we need to re-align the labels with the tokens.\n",
    "- Use `.word_ids()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bank', 'mand', 'ir', 'haji', 'jua', ',', 'kota', 'baru']\n",
      "['<s>', '▁bank', '▁mand', '▁ir', '▁haji', '▁ju', 'a', '▁', ',', '▁kota', '▁baru', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[None, 0, 1, 2, 3, 4, 4, 5, 5, 6, 7, None]\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[idx])\n",
    "print(tokenizer.convert_ids_to_tokens(train_encodings[\"input_ids\"][idx]))\n",
    "print(tokenizer(train_texts, is_split_into_words=True).word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(texts, tags, tokenizer, label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(texts, padding=True, truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for i, label in enumerate(tags):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            \n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "                \n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_encodings = tokenize_and_align_labels(train_texts, train_tag_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the re-aligned labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_ids</th>\n",
       "      <td>0</td>\n",
       "      <td>4620</td>\n",
       "      <td>14134</td>\n",
       "      <td>193</td>\n",
       "      <td>117790</td>\n",
       "      <td>1129</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>20553</td>\n",
       "      <td>3510</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁bank</td>\n",
       "      <td>▁mand</td>\n",
       "      <td>▁ir</td>\n",
       "      <td>▁haji</td>\n",
       "      <td>▁ju</td>\n",
       "      <td>a</td>\n",
       "      <td>▁</td>\n",
       "      <td>,</td>\n",
       "      <td>▁kota</td>\n",
       "      <td>▁baru</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>-100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2    3       4     5   6  7  8      9      10  \\\n",
       "input_ids     0   4620  14134  193  117790  1129  11  6  4  20553   3510   \n",
       "tokens      <s>  ▁bank  ▁mand  ▁ir   ▁haji   ▁ju   a  ▁  ,  ▁kota  ▁baru   \n",
       "labels     -100      2      2    2       1     1   1  1  1      1      1   \n",
       "\n",
       "             11     12     13     14     15     16     17     18     19  \n",
       "input_ids     2      1      1      1      1      1      1      1      1  \n",
       "tokens     </s>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  \n",
       "labels     -100   -100   -100   -100   -100   -100   -100   -100   -100  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"input_ids\"] = train_encodings.input_ids[0]\n",
    "df[\"tokens\"] = tokenizer.convert_ids_to_tokens(train_encodings.input_ids[0])\n",
    "df[\"labels\"] = train_encodings.labels[0]\n",
    "df[:20].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddressDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tag2id, tokenizer, tokenize_and_align_labels):\n",
    "        tokens = df[\"tokens\"].to_list()\n",
    "        labels = df[\"label\"].to_list()\n",
    "        tags = [[tag2id[x] for x in sample] for sample in labels]\n",
    "        \n",
    "        self.encodings = tokenize_and_align_labels(tokens, tags, tokenizer)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"labels\"])\n",
    "    \n",
    "train_dataset = AddressDataset(train_df, tag2id, tokenizer, tokenize_and_align_labels)\n",
    "val_dataset = AddressDataset(val_df, tag2id, tokenizer, tokenize_and_align_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the dataset is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_ids</th>\n",
       "      <td>0</td>\n",
       "      <td>4620</td>\n",
       "      <td>14134</td>\n",
       "      <td>193</td>\n",
       "      <td>117790</td>\n",
       "      <td>1129</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>20553</td>\n",
       "      <td>3510</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁bank</td>\n",
       "      <td>▁mand</td>\n",
       "      <td>▁ir</td>\n",
       "      <td>▁haji</td>\n",
       "      <td>▁ju</td>\n",
       "      <td>a</td>\n",
       "      <td>▁</td>\n",
       "      <td>,</td>\n",
       "      <td>▁kota</td>\n",
       "      <td>▁baru</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>-100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2    3       4     5   6  7  8      9      10  \\\n",
       "input_ids     0   4620  14134  193  117790  1129  11  6  4  20553   3510   \n",
       "tokens      <s>  ▁bank  ▁mand  ▁ir   ▁haji   ▁ju   a  ▁  ,  ▁kota  ▁baru   \n",
       "labels     -100      2      2    2       1     1   1  1  1      1      1   \n",
       "\n",
       "             11     12     13     14     15     16     17     18     19  \n",
       "input_ids     2      1      1      1      1      1      1      1      1  \n",
       "tokens     </s>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  \n",
       "labels     -100   -100   -100   -100   -100   -100   -100   -100   -100  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "df = pd.DataFrame()\n",
    "df[\"input_ids\"] = sample[\"input_ids\"]\n",
    "df[\"tokens\"] = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"])\n",
    "df[\"labels\"] = sample[\"labels\"]\n",
    "df[:20].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased', num_labels=len(unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class ComputeMetrics:\n",
    "    def __init__(self, id2tag):\n",
    "        self.id2tag = id2tag\n",
    "    \n",
    "    def compute(self, p):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [self.id2tag[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [self.id2tag[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        return {\n",
    "            \"precision\": precision_score(true_labels, true_predictions),\n",
    "            \"recall\": recall_score(true_labels, true_predictions),\n",
    "            \"f1\":f1_score(true_labels, true_predictions),\n",
    "            \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
    "        }\n",
    "\n",
    "compute_metrics = ComputeMetrics(id2tag).compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `Trainer` to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.273500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=1.2702716588974, metrics={'train_runtime': 2.7208, 'train_samples_per_second': 4.41, 'total_flos': 50173244100000.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 66156536, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 283842, 'init_mem_gpu_peaked_delta': 544821248, 'train_mem_cpu_alloc_delta': 164478, 'train_mem_gpu_alloc_delta': 534162944, 'train_mem_cpu_peaked_delta': 786081, 'train_mem_gpu_peaked_delta': 983777792})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=64,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ner]",
   "language": "python",
   "name": "conda-env-ner-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
